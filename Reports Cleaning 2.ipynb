{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7bbb31c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_csv('C://Users//kk//Downloads//SHNDOnlyRad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba7143f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>657357</td>\n",
       "      <td>657357</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>[**Last Name (LF) **],[**First Name3 (LF) **] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>728603</td>\n",
       "      <td>728603</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>[**2153-1-12**] 10:03 PM\\n CHEST (PORTABLE AP)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>728604</td>\n",
       "      <td>728604</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>[**2145-3-13**] 2:58 AM\\n CT ABDOMEN W/CONTRAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>728605</td>\n",
       "      <td>728605</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>[**2119-3-11**] 11:46 AM\\n CT HEAD W/O CONTRAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>732765</td>\n",
       "      <td>732765</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>[**2152-7-18**] 1:06 PM\\n CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1   CATEGORY  \\\n",
       "0      657357        657357  Radiology   \n",
       "1      728603        728603  Radiology   \n",
       "2      728604        728604  Radiology   \n",
       "3      728605        728605  Radiology   \n",
       "4      732765        732765  Radiology   \n",
       "\n",
       "                                                TEXT  \n",
       "0  [**Last Name (LF) **],[**First Name3 (LF) **] ...  \n",
       "1  [**2153-1-12**] 10:03 PM\\n CHEST (PORTABLE AP)...  \n",
       "2  [**2145-3-13**] 2:58 AM\\n CT ABDOMEN W/CONTRAS...  \n",
       "3  [**2119-3-11**] 11:46 AM\\n CT HEAD W/O CONTRAS...  \n",
       "4  [**2152-7-18**] 1:06 PM\\n CHEST (PORTABLE AP) ...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2ef1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(data=list(df1['TEXT']),columns=['Text'])\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5773c0f2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract headings\n",
    "import regex as re\n",
    "def list_elements():\n",
    "    list1=[]\n",
    "    for i in range(len(df2['Text'])):\n",
    "        x1=df2['Text'][i]\n",
    "        list1.append(x1)\n",
    "    return list1\n",
    "def get_headings(list1):\n",
    "    extra_list=[]\n",
    "    for i in range(len(list1)):\n",
    "        x1=list1[i]\n",
    "        x1=x1.replace('\\n',' ')\n",
    "        new=re.findall(r'[A-Za-z]+:',x1)\n",
    "        extra_list.append(new)\n",
    "    list04=[x1.lower() for x2 in extra_list for x1 in x2]\n",
    "    final_head=set(list04)\n",
    "    final_head=list(final_head)\n",
    "    return final_head\n",
    "new_list=list_elements()\n",
    "headings=get_headings(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe3074",
   "metadata": {},
   "outputs": [],
   "source": [
    "re3='i[A-Za-z]+ss[A-Za-z]+:'\n",
    "findings_impression=[x1[0] for x1 in [re.findall(re3,i) for i in headings] if x1 != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(findings_impression),len(findings_vocab)\n",
    "#... so these are number of words related to findings and impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7fd65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_list=[i for i in headings if i.startswith('fi')]\n",
    "re2=r'fi[A-Za-z]+ng[A-Za-z]+:'\n",
    "findings_vocab=[x1[0] for x1 in [re.findall(re2,i) for i in find_list] if x1 != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'findings:' in findings_vocab:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54ecfcc4",
   "metadata": {},
   "source": [
    "Here some additional tokens are remove from data and original position is added in your data for validation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "255ec4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check if a sentence contains a double findings and impression scenario\n",
    "def prepare_text_data(x):\n",
    "    x=x.replace('\\n',' ')\n",
    "    x=x.lower()\n",
    "    return x\n",
    "x1=pd.DataFrame(data=[*range(0,len(df2['Text']))])\n",
    "df3=pd.concat([df2,x1],axis=1,join='outer')\n",
    "df3.rename(columns={'TEXT':'Text',0:'Original_position'},inplace=True)\n",
    "df3['cleared']=df3['Text'].apply(prepare_text_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ba4c694",
   "metadata": {},
   "source": [
    "To check those reports which contain double findings and impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03aaef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findings_length():\n",
    "    list2=[]\n",
    "    regex1=r'findings:'\n",
    "    for c,i in enumerate(df3['cleared']):\n",
    "        x1=re.findall(regex1,i)\n",
    "        if len(x1)>=2: \n",
    "            list2.append([c,len(x1)])\n",
    "    return list2\n",
    "def impression_length():\n",
    "    list2=[]\n",
    "    regex1=r'impression:'\n",
    "    for c,i in enumerate(df3['cleared']):\n",
    "        x1=re.findall(regex1,i)\n",
    "        if len(x1)>=2: \n",
    "            list2.append([c,len(x1)])\n",
    "    return list2\n",
    "length_double_findings=findings_length()\n",
    "length_double_impression=impression_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f799f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2355, 2811)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(length_double_findings),len(length_double_impression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cad1a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "findings_length_index=[i[0] for i in length_double_findings]\n",
    "impression_length_index=[i[0] for i in length_double_impression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fcc1e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The findings and impression without set double are 5166 and with applying set 4438\n"
     ]
    }
   ],
   "source": [
    "final_double_list=findings_length_index.copy()\n",
    "final_double_list.extend(impression_length_index)\n",
    "final_double_list_new=list(set(final_double_list))\n",
    "print(f'The findings and impression without set double are {len(final_double_list)} \\\n",
    "and with applying set {len(final_double_list_new)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a80e7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df3.copy()\n",
    "df4.drop(labels=final_double_list_new,inplace=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbbd75b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe size is (522279, 4) and Reduced dataframe length is (517841, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'Original Dataframe size is {df1.shape} and Reduced dataframe length is {df4.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f0ea0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperation(one_string):\n",
    "    for x in re.finditer(r'findings:',one_string):\n",
    "        return ((x.start(), x.end()))\n",
    "df4['finding_list_Position']=df4['cleared'].apply(seperation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83753041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "209f3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad92f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.reset_index(inplace=True)\n",
    "df5.drop(labels='index',axis=1,inplace=True)\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df5['Text'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "caad6277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finding_text(df5):\n",
    "    list1=[]\n",
    "    for values,comp in enumerate(df5['cleared']):\n",
    "        x2=df5['finding_list_Position'][values][0]\n",
    "        list1.append(comp[x2+10:])\n",
    "    return list1\n",
    "clear_findings=get_finding_text(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "009b22b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "if 'impression:' in clear_findings[0].split(' '):\n",
    "    print(True)\n",
    "if 'impression:' in headings:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1493041",
   "metadata": {},
   "source": [
    "These extract index of headings after findings in radiology report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9b9cce0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lets use some other metric to extract findings frtom data\n",
    "def check_impression(clear_findings):\n",
    "    end=[]\n",
    "    for string_number,i1 in enumerate(clear_findings):\n",
    "        x=i1.split(' ')\n",
    "        for x1 in x: \n",
    "            if x1 in headings:\n",
    "                end.append(f\"word is {x1} and index is {x.index(x1)} for string {string_number}\")\n",
    "                break\n",
    "    return end\n",
    "end_Findings=check_impression(clear_findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ffa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpretation\n",
    "clear_findings[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5cb347d6",
   "metadata": {},
   "source": [
    "Check for consecutive findings and impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd2f5247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146837, 180617)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list99=[i.split(' ')[2]  for i in end_Findings]\n",
    "list98=list(filter(lambda x : x=='impression:',list99))\n",
    "len(list98),len(list99)\n",
    "# so 146387 reports have consecutive findings and impression headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c10b5523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some exceptions like "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e8c8102",
   "metadata": {},
   "source": [
    "Now extract some insights related to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6182b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_existence=[f'{list99.count(i1)} for word {i1}' for i1 in list(set(list99))]\n",
    "new_existence=[(int(i2.split(' ')[0]),i2.split(' ')[3]) for i2 in [f'{list99.count(i1)} for word {i1}' for i1 in list(set(list99))]]\n",
    "sorting_ex=sorted(list(filter(lambda x: x[0]>15,new_existence)),key=lambda x : x[0],reverse=True)\n",
    "list_rm_headings=[i[0] for i in sorting_ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230a7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorting_ex)\n",
    "print(list_rm_headings)\n",
    "# so why i am doing this because i want to remove such headings which have affectance on extracting impression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe5fa7f0",
   "metadata": {},
   "source": [
    "Use Regex to Extract Consecutive findings and impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4760905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_only_impression=list(filter(lambda x:x[0]=='impression:',[(i1.split(' ')[2],int(i1.split(' ')[6]),int(i1.split(' ')[9])) for i1 in end_Findings]))\n",
    "consecutive=[clear_findings[value[2]] for value in values_only_impression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40a2d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_findings(findings):\n",
    "    get_only_findings=[]\n",
    "    for finding in findings:\n",
    "        result=re.split(r'[A-Za-z]+:',finding)[0].strip()\n",
    "        get_only_findings.append(result)\n",
    "    return get_only_findings\n",
    "findings=extract_findings(consecutive)\n",
    "                                                         #...Note...........\n",
    "# In order to compare these extracted findings with original findings use df5 dataframe to compare\n",
    "# and in order to compare you need values_only_impression list --> and the value at third index is same as df5\n",
    "def extract_impression(findings):\n",
    "    #get_only_impression=[]\n",
    "    #for finding in findings:\n",
    "        #result=re.split(r'[A-Za-z]+:',finding)[1].strip()\n",
    "    result=[re.split(r'[A-Za-z]+:',finding)[1].strip() for finding in findings]\n",
    "    final_result=[re.split(r'[A-Za-z]+:',impression)[0].strip() for impression in result]\n",
    "        #get_only_impression.append(result)\n",
    "    return final_result\n",
    "impressions=extract_impression(consecutive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c28d47b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146837, 146837)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(impressions),len(findings)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c03b235f",
   "metadata": {},
   "source": [
    "Creating DataFrame using these findings and impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f5207dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned=pd.DataFrame(data={'findings':findings,'impressions':impressions})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4971cab6",
   "metadata": {},
   "source": [
    "Refining impressions so that to remove (over) and everything after it from impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fdf877de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def everything_over(x):\n",
    "    get_list=x.split(' ')\n",
    "    if '(over)' in get_list:\n",
    "        text=' '.join([get_list[:get_list.index(i1)]  for i1 in x.split(' ') if i1=='(over)'][0])\n",
    "        return text.strip()\n",
    "    else:\n",
    "        return x.strip()\n",
    "data_cleaned['impressions']=data_cleaned['impressions'].apply(everything_over)\n",
    "#va1=everything_over(str(data_cleaned['impressions'].iloc[-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fca6fba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.  new placement of aortic balloon pump and swan-ganz catheter.  2.  no change in left lower lobe and right perihilar consolidation.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned['impressions'].iloc[75654]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62a62c72",
   "metadata": {},
   "source": [
    "Remove such indexes where length of findings is smaller than impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f436b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_check(x):\n",
    "    len1=len(x.split(' '))\n",
    "    return len1\n",
    "results=[data_cleaned[i1].apply(length_check) for i1 in list(data_cleaned.columns)]\n",
    "findings_length,impression_length=list(results[0]),list(results[1])\n",
    "data2=pd.DataFrame(data={'findings_length':findings_length,'impression_length':impression_length})\n",
    "fin=pd.concat([data_cleaned,data2],axis=1)\n",
    "index_to_remove=list(fin[fin['impression_length']>=fin['findings_length']].index)\n",
    "fin.drop(index=index_to_remove,inplace=True)\n",
    "final_data=fin.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "899aa18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=fin.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0c5c2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data[\"half_length\"]=final_data[\"findings_length\"].apply(lambda x : int(x/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3208e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data[final_data[\"half_length\"]<=final_data[\"impression_length\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d549e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_data[(final_data[\"half_length\"]>=final_data[\"findings_length\"]) | (final_data[\"findings_length\"]>100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7206fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets make an assumption to only including findings with length almost 100\n",
    "final_data_reports=final_data[final_data[\"findings_length\"]<=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "de3bea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_reports=final_data_reports[final_data_reports[\"half_length\"]>=final_data_reports[\"impression_length\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b36a719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_data_reports[final_data_reports[\"impression_length\"]>=final_data_reports[\"half_length\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "32ba084a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "980df601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english')) \n",
    "def clean_data(list1,name,new_list1):\n",
    "    for i in list1:\n",
    "        i=str(i)\n",
    "        new_string = re.sub(r'[^\\w\\s]', '', i)\n",
    "        pattern = r'[0-9]'\n",
    "        new_string1 = re.sub(pattern, '', new_string)\n",
    "        new_string2 = re.sub(r'\\([^)]*\\)', '', new_string1)\n",
    "        new_string1=new_string2.lower()\n",
    "        if name=='findings':\n",
    "            tokens = [w for w in new_string1.split() if not w in stop_words]\n",
    "            tokens=' '.join(tokens)\n",
    "            new_list1.append(tokens)\n",
    "        elif name=='impressions':\n",
    "            new_list1.append(new_string1)\n",
    "    return new_list1\n",
    "x1=[]\n",
    "list1=clean_data(list(final_data_reports['findings']),final_data_reports['findings'].name,x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9bae001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=[]\n",
    "list2=clean_data(list(final_data_reports['impressions']),final_data_reports['impressions'].name,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "36fb3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_further(list1):\n",
    "    list5=[]\n",
    "    for i in list1:\n",
    "        i=str(i)\n",
    "        list1=i.split(' ')\n",
    "        for i in range(list1.count('')):\n",
    "            list1.remove('')\n",
    "        x1=' '.join(list1)\n",
    "        list5.append(x1)\n",
    "    return list5\n",
    "list6=clean_further(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c7660bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "list7=clean_further(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8c87fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_training=pd.DataFrame({'findings':list6,\n",
    "                'impression':list7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c38a58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_training\n",
    "data_for_training.to_csv(\"C://Users//kk//Downloads//Assumption_Based.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66598098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_for_training=pd.read_csv(\"C://Users//kk//Downloads//Assumption_Based.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d5e3050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>previously seen hyperintensities flare sequenc...</td>\n",
       "      <td>small foci of bilateral calcification within t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>stable cardiomegaly without evidence pulmonary...</td>\n",
       "      <td>picc line terminates at mid svc without eviden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>heart stably enlarged patient status post cabg...</td>\n",
       "      <td>stable cardiomegaly minimal if any cardiac fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>stable cardiomegaly minimal upper lung zone re...</td>\n",
       "      <td>no evidence of pneumonia stable cardiomegaly a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tip right sided picc line seen overlying proxi...</td>\n",
       "      <td>tip of rightsided picc line overlying the prox...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76139</th>\n",
       "      <td>76139</td>\n",
       "      <td>suspicious liver lesions identified biliary di...</td>\n",
       "      <td>no focal liver lesion identified cholelithiasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76140</th>\n",
       "      <td>76140</td>\n",
       "      <td>grayscale color doppler images obtained right ...</td>\n",
       "      <td>no evidence of deep vein thrombosis in the rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76141</th>\n",
       "      <td>76141</td>\n",
       "      <td>portable chest radiograph demonstrates focal c...</td>\n",
       "      <td>no acute cardiopulmonary process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76142</th>\n",
       "      <td>76142</td>\n",
       "      <td>ap upright lateral chest radiograph obtained l...</td>\n",
       "      <td>no acute intrathoracic process with left later...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76143</th>\n",
       "      <td>76143</td>\n",
       "      <td>right kidney measures cm left kidney measures ...</td>\n",
       "      <td>normal renal ultrasound no stone or hydronephr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76144 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                           findings  \\\n",
       "0               0  previously seen hyperintensities flare sequenc...   \n",
       "1               1  stable cardiomegaly without evidence pulmonary...   \n",
       "2               2  heart stably enlarged patient status post cabg...   \n",
       "3               3  stable cardiomegaly minimal upper lung zone re...   \n",
       "4               4  tip right sided picc line seen overlying proxi...   \n",
       "...           ...                                                ...   \n",
       "76139       76139  suspicious liver lesions identified biliary di...   \n",
       "76140       76140  grayscale color doppler images obtained right ...   \n",
       "76141       76141  portable chest radiograph demonstrates focal c...   \n",
       "76142       76142  ap upright lateral chest radiograph obtained l...   \n",
       "76143       76143  right kidney measures cm left kidney measures ...   \n",
       "\n",
       "                                              impression  \n",
       "0      small foci of bilateral calcification within t...  \n",
       "1      picc line terminates at mid svc without eviden...  \n",
       "2      stable cardiomegaly minimal if any cardiac fai...  \n",
       "3      no evidence of pneumonia stable cardiomegaly a...  \n",
       "4      tip of rightsided picc line overlying the prox...  \n",
       "...                                                  ...  \n",
       "76139  no focal liver lesion identified cholelithiasi...  \n",
       "76140  no evidence of deep vein thrombosis in the rig...  \n",
       "76141                   no acute cardiopulmonary process  \n",
       "76142  no acute intrathoracic process with left later...  \n",
       "76143  normal renal ultrasound no stone or hydronephr...  \n",
       "\n",
       "[76144 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d79d4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "def detect_over(x):\n",
    "    #starting_position=[x1.start(),x1.end() for x1 in re.finditer(r'(over)',x)]\n",
    "    for x in re.finditer(r'(over):',x):\n",
    "        if x.start()==None:\n",
    "            return 'shit'\n",
    "        else:\n",
    "            return(x.start(),x.end())\n",
    "data_for_training[\"whether_exist\"]=data_for_training['findings'].apply(detect_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "acc54c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_training.drop(columns={'Unnamed: 0','whether_exist'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c46b532e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "findings       0\n",
       "impression    62\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_training.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6e1f170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_training.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9bf2eb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "findings      0\n",
       "impression    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_training.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c0712d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_for_training[data_for_training['whether_exist']=='shit']\n",
    "for i in list(data_for_training['impression']):\n",
    "    v1=re.findall(r'/(over/)',i)\n",
    "    if v1 ==[]:\n",
    "        pass\n",
    "    else:\n",
    "        print('over is present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6332adad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stable cardiomegaly without evidence pulmonary vascular redistribution mediastinal hilar contours normal rightsided duallumen catheter unchanged position tip mid svc new rightsided picc line extends mid svc well pneumothoraces identified lungs remain clear pleural effusions'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_for_training['findings'])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b8a5cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_training.drop(columns={'length_check'},inplace=True)\n",
    "data_for_training[\"length_check\"]=data_for_training['impression'].apply(lambda x : len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "82ea863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_drop=data_for_training[data_for_training['length_check']<=2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99c485c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_training.drop(labels=index_to_drop,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9d818620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_for_training.drop(columns={'length_check'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f5b748c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_training.to_csv('C://Users//kk//Downloads//cleaned_but_need_improvement.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975e987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
