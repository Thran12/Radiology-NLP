{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0vAbNuC4u9ET",
        "outputId": "76b106ab-a2c2-4eaa-b25f-cc3c78ad490a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fae77d03-7f73-44a1-99b3-34728226e165\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Original_position</th>\n",
              "      <th>findings</th>\n",
              "      <th>impressions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>there is no acute intracranial hemorrhage, mas...</td>\n",
              "      <td>1. no acute intracranial hemorrhage or mass ef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ap, lateral, and oblique views of the left foo...</td>\n",
              "      <td>comminuted intra-articular fracture proximal p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>the procedure was explained to the patient. a ...</td>\n",
              "      <td>uncomplicated ultrasound and fluoroscopically ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>the ventricles and extra-axial spaces are norm...</td>\n",
              "      <td>3-mm lesion within the left cerebellar hemisph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>there is no evidence of fracture, dislocation,...</td>\n",
              "      <td>no evidence of fracture or subluxation.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fae77d03-7f73-44a1-99b3-34728226e165')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fae77d03-7f73-44a1-99b3-34728226e165 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fae77d03-7f73-44a1-99b3-34728226e165');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  Original_position  \\\n",
              "0           0                  0   \n",
              "1           1                  1   \n",
              "2           2                  2   \n",
              "3           3                  3   \n",
              "4           4                  4   \n",
              "\n",
              "                                            findings  \\\n",
              "0  there is no acute intracranial hemorrhage, mas...   \n",
              "1  ap, lateral, and oblique views of the left foo...   \n",
              "2  the procedure was explained to the patient. a ...   \n",
              "3  the ventricles and extra-axial spaces are norm...   \n",
              "4  there is no evidence of fracture, dislocation,...   \n",
              "\n",
              "                                         impressions  \n",
              "0  1. no acute intracranial hemorrhage or mass ef...  \n",
              "1  comminuted intra-articular fracture proximal p...  \n",
              "2  uncomplicated ultrasound and fluoroscopically ...  \n",
              "3  3-mm lesion within the left cerebellar hemisph...  \n",
              "4         no evidence of fracture or subluxation.     "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df1=pd.read_csv('/content/drive/MyDrive/Extracted_Data.csv')\n",
        "df1.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTAmjlKDvWQ1",
        "outputId": "0fcd7881-29ae-40e2-9936-c63c7ccb3e3c"
      },
      "outputs": [],
      "source": [
        "x=list(df1.columns)\n",
        "x.remove('findings')\n",
        "x.remove('impressions')\n",
        "df2=df1.drop(x,axis=1)\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL4IP1TkvdwS",
        "outputId": "9d690e73-81d7-456b-ea89-95804bdeaeaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "findings       0\n",
            "impressions    0\n",
            "dtype: int64\n",
            "findings       0\n",
            "impressions    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df2.isna().sum())\n",
        "df2.dropna(axis=0,inplace=True)\n",
        "print(df2.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klJdhGNvgrOn",
        "outputId": "7192b093-2b9f-4b8b-f64f-4b333d4bbc01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxw4FXOgvlc8"
      },
      "outputs": [],
      "source": [
        "import regex as re\n",
        "from nltk.corpus import stopwords \n",
        "stop_words = set(stopwords.words('english')) \n",
        "def clean_data(list1,name,new_list1):\n",
        "    for i in list1:\n",
        "        i=str(i)\n",
        "        new_string = re.sub(r'[^\\w\\s]', '', i)\n",
        "        pattern = r'[0-9]'\n",
        "        new_string1 = re.sub(pattern, '', new_string)\n",
        "        new_string2 = re.sub(r'\\([^)]*\\)', '', new_string1)\n",
        "        new_string1=new_string2.lower()\n",
        "        if name=='findings':\n",
        "            tokens = [w for w in new_string1.split() if not w in stop_words]\n",
        "            tokens=' '.join(tokens)\n",
        "            new_list1.append(tokens)\n",
        "        elif name=='impressions':\n",
        "            new_list1.append(new_string1)\n",
        "    return new_list1\n",
        "x1=[]\n",
        "list1=clean_data(list(df2['findings']),df2['findings'].name,x1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI0FIdTevl5T"
      },
      "outputs": [],
      "source": [
        "x2=[]\n",
        "list2=clean_data(list(df2['impressions']),df2['impressions'].name,x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ-CuZD-xE-5"
      },
      "outputs": [],
      "source": [
        "def clean_further(list1):\n",
        "    list5=[]\n",
        "    for i in list1:\n",
        "        i=str(i)\n",
        "        list1=i.split(' ')\n",
        "        for i in range(list1.count('')):\n",
        "            list1.remove('')\n",
        "        x1=' '.join(list1)\n",
        "        list5.append(x1)\n",
        "    return list5\n",
        "list6=clean_further(list1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoVBUV7Yxnqm"
      },
      "outputs": [],
      "source": [
        "list7=clean_further(list2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AUuTd84Txpkt",
        "outputId": "4385aea0-1770-4b60-999c-9c88eb8c9782"
      },
      "outputs": [],
      "source": [
        "df3=pd.DataFrame({'findings':list6,\n",
        "                'impression':list7})\n",
        "df3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwbsvWcExsS2"
      },
      "outputs": [],
      "source": [
        "df3['impression'] = df3['impression'].apply(lambda x : '_START_ '+ x + ' _END_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKqq9VDcxz_W",
        "outputId": "da15a6d8-45aa-4608-dc60-b581ab9fc5cf"
      },
      "outputs": [],
      "source": [
        "import random as rnd\n",
        "def get_any_data(times,which):\n",
        "    for i in range(times):\n",
        "        x1=rnd.randint(0,len(df3['findings']))\n",
        "        print(x1)\n",
        "        print(df3[which][x1])\n",
        "        print(df3['impression'][x1])\n",
        "        print('--------')\n",
        "get_any_data(3,'findings')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "B7pzdEPgx3or",
        "outputId": "83cb0f3d-368e-426b-c0c7-fb089e5afba4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "# populate the lists with sentence lengths\n",
        "for i in df3['findings']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "for i in df3['impression']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1kAmWFCx9HK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(df3['findings'],df3['impression'],test_size=0.1,random_state=42,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9kvcYelyFL6",
        "outputId": "c5a7b971-5a32-4f4a-aee9-941fb48a2633"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2568,)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEtw2uKntGnn",
        "outputId": "f1d869bb-3909-44c1-9777-a370d916259d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "209\n"
          ]
        }
      ],
      "source": [
        "list_len=[len(i.split()) for i in df3['impression']]\n",
        "print(max(list_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NItNCoWsyI61"
      },
      "outputs": [],
      "source": [
        "max_len_text=200\n",
        "max_len_summary=190\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "in_tokenizer = Tokenizer()\n",
        "in_tokenizer.fit_on_texts(X_train)\n",
        "tr_tokenizer = Tokenizer()\n",
        "tr_tokenizer.fit_on_texts(y_train)\n",
        "X_train= in_tokenizer.texts_to_sequences(X_train) \n",
        "y_train= tr_tokenizer.texts_to_sequences(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkSkqfluycDn"
      },
      "outputs": [],
      "source": [
        "en_in_data= pad_sequences(X_train,  maxlen=max_len_text, padding='post') \n",
        "dec_data= pad_sequences(y_train,  maxlen=max_len_summary, padding='post')\n",
        "dec_in_data = dec_data[:,:-1]\n",
        "dec_tr_data = dec_data.reshape(len(dec_data),max_len_summary,1)[:,1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBiCWPknMyAU"
      },
      "outputs": [],
      "source": [
        "x_voc_size   =  len(in_tokenizer.word_index) +1\n",
        "y_voc_size   =  len(tr_tokenizer.word_index) +1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqJDj8TXhrxn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_wy5e83306W"
      },
      "outputs": [],
      "source": [
        "size_of_vocab=len(in_tokenizer.word_index)+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_V4qX1ZtjT1"
      },
      "source": [
        "So this the technique of using embedding matrix and embedding vectors as embedding layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX5wpyB1mveb",
        "outputId": "47f9405c-a503-49cc-bd93-400cada78842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 44082 word vectors.\n",
            "(100,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "#embedding Layer creation\n",
        "from gensim.models import Word2Vec\n",
        "best_model=Word2Vec.load('/content/drive/MyDrive/word2vec+fastText/word2vec.model')\n",
        "vocab_len_size = best_model.wv.index2word\n",
        "dict1={}\n",
        "for i in range(len(best_model.wv.index2word)):\n",
        "  keys=list(best_model.wv.vocab.keys())[i]\n",
        "  vector1=best_model.wv.vectors[i]\n",
        "  dict1[f'{keys}']=vector1\n",
        "with open('/content/drive/MyDrive/custom_embeddings_word2vec.txt', 'w+') as f:\n",
        "    for token, vector in dict1.items():\n",
        "        vector_str = ' '.join([str(v) for v in vector])\n",
        "        f.write(f'{token} {vector_str}\\n')\n",
        "embeddings_index = dict()\n",
        "f = open('/content/drive/MyDrive/custom_embeddings_word2vec.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "x_voc_size=44082\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "from keras.layers import Embedding\n",
        "embedding_matrix = np.zeros((x_voc_size, 100))\n",
        "\n",
        "#..so here the x_voc_size need to be replace by 44082 and 130 need to be replaced with 100\n",
        "\n",
        "for word, i in in_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(len(dict1)+1,\n",
        "                            130,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_len_text,\n",
        "                            trainable=False)\n",
        "#print(embedding_matrix.shape)\n",
        "'''list_embeddings=list(dict1.keys())\n",
        "if 'endotracheal' in list_embeddings:\n",
        "  print(True)\n",
        "else:\n",
        "  print(False)'''\n",
        "embedding_layer=Embedding(x_voc_size,100,weights=[embedding_matrix],input_length=max_len_text,trainable=False)\n",
        "print(embedding_matrix[3].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uue9IHdBuX6J",
        "outputId": "2f449321-0c6b-410d-fc9d-3282d71304fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44082"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(embedding_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKTMzKQVwTSC"
      },
      "outputs": [],
      "source": [
        "#import json\n",
        "#with open('/content/drive/MyDrive/data.json') as json_file:\n",
        " #   data = json.load(json_file)\n",
        "  #  print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UBskFuNwSV6"
      },
      "outputs": [],
      "source": [
        "#list1=list(data.values())\n",
        "#print(list1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVnffMf6vSxL"
      },
      "source": [
        "Using Clinical Bert Embeddings.Just Clinical Bert.\n",
        "Next target is to use Clinical Biobert as your embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4RzGgMZht6I",
        "outputId": "a177852c-2aa1-45e6-e2e3-e1f6f85a796e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        multiple             4408200     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200, 100),   80400       ['embedding_1[0][0]']            \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 200, 100),   80400       ['lstm[0][0]']                   \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 100)    444300      ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 200, 100),   80400       ['lstm_1[0][0]']                 \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  [(None, None, 100),  80400       ['embedding[0][0]',              \n",
            "                                 (None, 100),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 100)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, None, 100)    0           ['lstm_4[0][0]',                 \n",
            "                                                                  'lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " concat_layer1 (Concatenate)    (None, None, 200)    0           ['lstm_4[0][0]',                 \n",
            "                                                                  'attention[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 44082)  8860482     ['concat_layer1[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,034,582\n",
            "Trainable params: 9,626,382\n",
            "Non-trainable params: 4,408,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "import tensorflow.keras.layers\n",
        "import tensorflow.keras.models\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.layers import Attention\n",
        "\n",
        "K.clear_session() \n",
        "latent_dim = 100\n",
        " \n",
        "#create input object of total number of encoder words\n",
        "#en_inputs = Input(shape=(max_len_text,)) \n",
        "#en_embedding = Embedding(x_voc_size, latent_dim,trainable=True)(en_inputs) \n",
        "\n",
        "#... adding a custom layer in place of this embedding layer for custom embedding scenario\n",
        "sequence_input = Input(shape=(max_len_text,), dtype='int32')\n",
        "en_embedding = embedding_layer(sequence_input)\n",
        "\n",
        "\n",
        "#1st LSTM Layer\n",
        "en_lstm1= LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "en_outputs1, state_h1, state_c1= en_lstm1(en_embedding) \n",
        "#2nd LSTM Layer\n",
        "en_lstm2= LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "en_outputs2, state_h2, state_c2= en_lstm2(en_outputs1) \n",
        "#3rd LSTM Layer\n",
        "en_lstm3= LSTM(latent_dim,return_sequences=True,return_state=True)\n",
        "en_outputs3 , state_h3 , state_c3= en_lstm3(en_outputs2)\n",
        "#encoder states\n",
        "en_states= [state_h3, state_c3]\n",
        "\n",
        "#---------------------------------\n",
        "\n",
        "\n",
        "# Decoder. \n",
        "'''dec_inputs = Input(shape=(None,)) \n",
        "\n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim) \n",
        "dec_embedding = dec_emb_layer(dec_inputs) '''\n",
        "\n",
        "#.using the custom decoder Layer\n",
        "#................................................\n",
        "\n",
        "dec_inputs = Input(shape=(None,), dtype='int32')\n",
        "dec_embedding = embedding_layer(dec_inputs)\n",
        " \n",
        "#initialize decoder's LSTM layer with the output states of encoder\n",
        "dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "dec_outputs, *_ = dec_lstm(dec_embedding,initial_state=en_states) \n",
        "\n",
        "'''# Decoder. \n",
        "dec_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim) \n",
        "dec_embedding = dec_emb_layer(dec_inputs) \n",
        " \n",
        "#initialize decoder's LSTM layer with the output states of encoder\n",
        "dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "dec_outputs, *_ = dec_lstm(dec_embedding,initial_state=en_states)'''\n",
        "\n",
        "#Attention layer\n",
        "attention =Attention()\n",
        "attn_out = attention([dec_outputs,en_outputs3])\n",
        " \n",
        "#Concatenate the attention output with the decoder outputs\n",
        "merge=Concatenate(axis=-1, name='concat_layer1')([dec_outputs,attn_out]) \n",
        "#Dense layer (output layer)\n",
        "dec_dense = Dense(x_voc_size, activation='softmax') \n",
        "dec_outputs = dec_dense(merge) \n",
        "\n",
        "model = Model([sequence_input, dec_inputs],dec_outputs) \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljtt0y3dh1Ct"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KhnEVPeiZlI"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "#maybe changing the optimizer and loss function can help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRXSLKZQibx_",
        "outputId": "f6fe3b56-163c-4102-b518-40f08a8a3b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "21/21 [==============================] - 16s 714ms/step - loss: 5.0921 - val_loss: 1.5014\n",
            "Epoch 2/200\n",
            "21/21 [==============================] - 14s 657ms/step - loss: 1.2654 - val_loss: 1.1841\n",
            "Epoch 3/200\n",
            "21/21 [==============================] - 14s 659ms/step - loss: 1.0517 - val_loss: 1.0383\n",
            "Epoch 4/200\n",
            "21/21 [==============================] - 14s 660ms/step - loss: 0.9664 - val_loss: 1.0023\n",
            "Epoch 5/200\n",
            "21/21 [==============================] - 14s 664ms/step - loss: 0.9362 - val_loss: 0.9830\n",
            "Epoch 6/200\n",
            "21/21 [==============================] - 14s 665ms/step - loss: 0.9168 - val_loss: 0.9725\n",
            "Epoch 7/200\n",
            "21/21 [==============================] - 14s 663ms/step - loss: 0.9039 - val_loss: 0.9653\n",
            "Epoch 8/200\n",
            "21/21 [==============================] - 14s 669ms/step - loss: 0.8931 - val_loss: 0.9565\n",
            "Epoch 9/200\n",
            "21/21 [==============================] - 14s 682ms/step - loss: 0.8812 - val_loss: 0.9460\n",
            "Epoch 10/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.8663 - val_loss: 0.9305\n",
            "Epoch 11/200\n",
            "21/21 [==============================] - 14s 669ms/step - loss: 0.8468 - val_loss: 0.9147\n",
            "Epoch 12/200\n",
            "21/21 [==============================] - 14s 666ms/step - loss: 0.8302 - val_loss: 0.9026\n",
            "Epoch 13/200\n",
            "21/21 [==============================] - 14s 670ms/step - loss: 0.8148 - val_loss: 0.8926\n",
            "Epoch 14/200\n",
            "21/21 [==============================] - 14s 666ms/step - loss: 0.8019 - val_loss: 0.8815\n",
            "Epoch 15/200\n",
            "21/21 [==============================] - 14s 668ms/step - loss: 0.7904 - val_loss: 0.8729\n",
            "Epoch 16/200\n",
            "21/21 [==============================] - 14s 667ms/step - loss: 0.7785 - val_loss: 0.8654\n",
            "Epoch 17/200\n",
            "21/21 [==============================] - 14s 668ms/step - loss: 0.7677 - val_loss: 0.8594\n",
            "Epoch 18/200\n",
            "21/21 [==============================] - 14s 670ms/step - loss: 0.7573 - val_loss: 0.8472\n",
            "Epoch 19/200\n",
            "21/21 [==============================] - 14s 669ms/step - loss: 0.7459 - val_loss: 0.8397\n",
            "Epoch 20/200\n",
            "21/21 [==============================] - 14s 671ms/step - loss: 0.7344 - val_loss: 0.8334\n",
            "Epoch 21/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.7232 - val_loss: 0.8235\n",
            "Epoch 22/200\n",
            "21/21 [==============================] - 14s 669ms/step - loss: 0.7124 - val_loss: 0.8151\n",
            "Epoch 23/200\n",
            "21/21 [==============================] - 14s 671ms/step - loss: 0.7008 - val_loss: 0.8086\n",
            "Epoch 24/200\n",
            "21/21 [==============================] - 14s 667ms/step - loss: 0.6900 - val_loss: 0.8051\n",
            "Epoch 25/200\n",
            "21/21 [==============================] - 14s 668ms/step - loss: 0.6804 - val_loss: 0.7951\n",
            "Epoch 26/200\n",
            "21/21 [==============================] - 14s 668ms/step - loss: 0.6698 - val_loss: 0.7892\n",
            "Epoch 27/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.6609 - val_loss: 0.7845\n",
            "Epoch 28/200\n",
            "21/21 [==============================] - 14s 668ms/step - loss: 0.6516 - val_loss: 0.7795\n",
            "Epoch 29/200\n",
            "21/21 [==============================] - 14s 667ms/step - loss: 0.6426 - val_loss: 0.7762\n",
            "Epoch 30/200\n",
            "21/21 [==============================] - 14s 667ms/step - loss: 0.6338 - val_loss: 0.7701\n",
            "Epoch 31/200\n",
            "21/21 [==============================] - 14s 670ms/step - loss: 0.6252 - val_loss: 0.7665\n",
            "Epoch 32/200\n",
            "21/21 [==============================] - 14s 669ms/step - loss: 0.6166 - val_loss: 0.7620\n",
            "Epoch 33/200\n",
            "21/21 [==============================] - 14s 670ms/step - loss: 0.6081 - val_loss: 0.7570\n",
            "Epoch 34/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.6000 - val_loss: 0.7523\n",
            "Epoch 35/200\n",
            "21/21 [==============================] - 14s 669ms/step - loss: 0.5924 - val_loss: 0.7497\n",
            "Epoch 36/200\n",
            "21/21 [==============================] - 14s 669ms/step - loss: 0.5840 - val_loss: 0.7464\n",
            "Epoch 37/200\n",
            "21/21 [==============================] - 14s 669ms/step - loss: 0.5764 - val_loss: 0.7436\n",
            "Epoch 38/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.5698 - val_loss: 0.7417\n",
            "Epoch 39/200\n",
            "21/21 [==============================] - 14s 671ms/step - loss: 0.5618 - val_loss: 0.7388\n",
            "Epoch 40/200\n",
            "21/21 [==============================] - 14s 671ms/step - loss: 0.5549 - val_loss: 0.7363\n",
            "Epoch 41/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.5478 - val_loss: 0.7346\n",
            "Epoch 42/200\n",
            "21/21 [==============================] - 14s 669ms/step - loss: 0.5412 - val_loss: 0.7310\n",
            "Epoch 43/200\n",
            "21/21 [==============================] - 14s 669ms/step - loss: 0.5339 - val_loss: 0.7305\n",
            "Epoch 44/200\n",
            "21/21 [==============================] - 14s 669ms/step - loss: 0.5281 - val_loss: 0.7279\n",
            "Epoch 45/200\n",
            "21/21 [==============================] - 14s 669ms/step - loss: 0.5210 - val_loss: 0.7278\n",
            "Epoch 46/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.5149 - val_loss: 0.7253\n",
            "Epoch 47/200\n",
            "21/21 [==============================] - 14s 670ms/step - loss: 0.5088 - val_loss: 0.7242\n",
            "Epoch 48/200\n",
            "21/21 [==============================] - 14s 671ms/step - loss: 0.5026 - val_loss: 0.7256\n",
            "Epoch 49/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.4971 - val_loss: 0.7221\n",
            "Epoch 50/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.4913 - val_loss: 0.7212\n",
            "Epoch 51/200\n",
            "21/21 [==============================] - 14s 670ms/step - loss: 0.4852 - val_loss: 0.7197\n",
            "Epoch 52/200\n",
            "21/21 [==============================] - 14s 669ms/step - loss: 0.4794 - val_loss: 0.7189\n",
            "Epoch 53/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.4742 - val_loss: 0.7198\n",
            "Epoch 54/200\n",
            "21/21 [==============================] - 14s 670ms/step - loss: 0.4688 - val_loss: 0.7193\n",
            "Epoch 55/200\n",
            "21/21 [==============================] - 14s 671ms/step - loss: 0.4628 - val_loss: 0.7201\n",
            "Epoch 56/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.4581 - val_loss: 0.7178\n",
            "Epoch 57/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.4527 - val_loss: 0.7195\n",
            "Epoch 58/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.4484 - val_loss: 0.7176\n",
            "Epoch 59/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.4421 - val_loss: 0.7174\n",
            "Epoch 60/200\n",
            "21/21 [==============================] - 14s 671ms/step - loss: 0.4377 - val_loss: 0.7191\n",
            "Epoch 61/200\n",
            "21/21 [==============================] - 14s 670ms/step - loss: 0.4329 - val_loss: 0.7173\n",
            "Epoch 62/200\n",
            "21/21 [==============================] - 14s 671ms/step - loss: 0.4275 - val_loss: 0.7195\n",
            "Epoch 63/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.4235 - val_loss: 0.7210\n",
            "Epoch 64/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.4186 - val_loss: 0.7192\n",
            "Epoch 65/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.4140 - val_loss: 0.7216\n",
            "Epoch 66/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.4092 - val_loss: 0.7185\n",
            "Epoch 67/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.4050 - val_loss: 0.7217\n",
            "Epoch 68/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.4006 - val_loss: 0.7209\n",
            "Epoch 69/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.3962 - val_loss: 0.7209\n",
            "Epoch 70/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.3918 - val_loss: 0.7218\n",
            "Epoch 71/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.3871 - val_loss: 0.7205\n",
            "Epoch 72/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.3832 - val_loss: 0.7227\n",
            "Epoch 73/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.3787 - val_loss: 0.7240\n",
            "Epoch 74/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.3743 - val_loss: 0.7246\n",
            "Epoch 75/200\n",
            "21/21 [==============================] - 14s 684ms/step - loss: 0.3710 - val_loss: 0.7253\n",
            "Epoch 76/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.3669 - val_loss: 0.7272\n",
            "Epoch 77/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.3626 - val_loss: 0.7263\n",
            "Epoch 78/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.3585 - val_loss: 0.7292\n",
            "Epoch 79/200\n",
            "21/21 [==============================] - 14s 671ms/step - loss: 0.3547 - val_loss: 0.7287\n",
            "Epoch 80/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.3508 - val_loss: 0.7278\n",
            "Epoch 81/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.3470 - val_loss: 0.7308\n",
            "Epoch 82/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.3433 - val_loss: 0.7323\n",
            "Epoch 83/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.3397 - val_loss: 0.7356\n",
            "Epoch 84/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.3361 - val_loss: 0.7355\n",
            "Epoch 85/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.3329 - val_loss: 0.7364\n",
            "Epoch 86/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.3284 - val_loss: 0.7361\n",
            "Epoch 87/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.3258 - val_loss: 0.7382\n",
            "Epoch 88/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.3211 - val_loss: 0.7391\n",
            "Epoch 89/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.3168 - val_loss: 0.7408\n",
            "Epoch 90/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.3138 - val_loss: 0.7408\n",
            "Epoch 91/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.3113 - val_loss: 0.7434\n",
            "Epoch 92/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.3084 - val_loss: 0.7464\n",
            "Epoch 93/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.3055 - val_loss: 0.7454\n",
            "Epoch 94/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.3018 - val_loss: 0.7483\n",
            "Epoch 95/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.2989 - val_loss: 0.7497\n",
            "Epoch 96/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.2963 - val_loss: 0.7498\n",
            "Epoch 97/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.2923 - val_loss: 0.7496\n",
            "Epoch 98/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.2894 - val_loss: 0.7567\n",
            "Epoch 99/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.2865 - val_loss: 0.7556\n",
            "Epoch 100/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.2829 - val_loss: 0.7560\n",
            "Epoch 101/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.2799 - val_loss: 0.7580\n",
            "Epoch 102/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.2770 - val_loss: 0.7594\n",
            "Epoch 103/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.2748 - val_loss: 0.7620\n",
            "Epoch 104/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.2707 - val_loss: 0.7650\n",
            "Epoch 105/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.2692 - val_loss: 0.7632\n",
            "Epoch 106/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.2657 - val_loss: 0.7664\n",
            "Epoch 107/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.2626 - val_loss: 0.7674\n",
            "Epoch 108/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.2605 - val_loss: 0.7691\n",
            "Epoch 109/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.2576 - val_loss: 0.7739\n",
            "Epoch 110/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.2548 - val_loss: 0.7739\n",
            "Epoch 111/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.2519 - val_loss: 0.7760\n",
            "Epoch 112/200\n",
            "21/21 [==============================] - 14s 670ms/step - loss: 0.2498 - val_loss: 0.7759\n",
            "Epoch 113/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.2464 - val_loss: 0.7789\n",
            "Epoch 114/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.2442 - val_loss: 0.7830\n",
            "Epoch 115/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.2419 - val_loss: 0.7839\n",
            "Epoch 116/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.2390 - val_loss: 0.7864\n",
            "Epoch 117/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.2368 - val_loss: 0.7874\n",
            "Epoch 118/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.2337 - val_loss: 0.7911\n",
            "Epoch 119/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.2309 - val_loss: 0.7876\n",
            "Epoch 120/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.2288 - val_loss: 0.7920\n",
            "Epoch 121/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.2270 - val_loss: 0.7933\n",
            "Epoch 122/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.2241 - val_loss: 0.7985\n",
            "Epoch 123/200\n",
            "21/21 [==============================] - 14s 680ms/step - loss: 0.2214 - val_loss: 0.7969\n",
            "Epoch 124/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.2197 - val_loss: 0.8013\n",
            "Epoch 125/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.2168 - val_loss: 0.8026\n",
            "Epoch 126/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.2145 - val_loss: 0.8027\n",
            "Epoch 127/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.2119 - val_loss: 0.8100\n",
            "Epoch 128/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.2098 - val_loss: 0.8112\n",
            "Epoch 129/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.2082 - val_loss: 0.8111\n",
            "Epoch 130/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.2051 - val_loss: 0.8147\n",
            "Epoch 131/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.2031 - val_loss: 0.8152\n",
            "Epoch 132/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.2011 - val_loss: 0.8136\n",
            "Epoch 133/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.1987 - val_loss: 0.8191\n",
            "Epoch 134/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1969 - val_loss: 0.8238\n",
            "Epoch 135/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1950 - val_loss: 0.8243\n",
            "Epoch 136/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.1923 - val_loss: 0.8236\n",
            "Epoch 137/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1896 - val_loss: 0.8282\n",
            "Epoch 138/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1878 - val_loss: 0.8343\n",
            "Epoch 139/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.1863 - val_loss: 0.8326\n",
            "Epoch 140/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1841 - val_loss: 0.8356\n",
            "Epoch 141/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1819 - val_loss: 0.8372\n",
            "Epoch 142/200\n",
            "21/21 [==============================] - 14s 678ms/step - loss: 0.1807 - val_loss: 0.8370\n",
            "Epoch 143/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1788 - val_loss: 0.8391\n",
            "Epoch 144/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.1761 - val_loss: 0.8414\n",
            "Epoch 145/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1742 - val_loss: 0.8444\n",
            "Epoch 146/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.1730 - val_loss: 0.8469\n",
            "Epoch 147/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.1704 - val_loss: 0.8452\n",
            "Epoch 148/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.1687 - val_loss: 0.8520\n",
            "Epoch 149/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1662 - val_loss: 0.8556\n",
            "Epoch 150/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1645 - val_loss: 0.8590\n",
            "Epoch 151/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.1631 - val_loss: 0.8560\n",
            "Epoch 152/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1614 - val_loss: 0.8621\n",
            "Epoch 153/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1599 - val_loss: 0.8624\n",
            "Epoch 154/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.1576 - val_loss: 0.8663\n",
            "Epoch 155/200\n",
            "21/21 [==============================] - 14s 680ms/step - loss: 0.1557 - val_loss: 0.8699\n",
            "Epoch 156/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1543 - val_loss: 0.8707\n",
            "Epoch 157/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1523 - val_loss: 0.8704\n",
            "Epoch 158/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1511 - val_loss: 0.8742\n",
            "Epoch 159/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.1491 - val_loss: 0.8758\n",
            "Epoch 160/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.1473 - val_loss: 0.8763\n",
            "Epoch 161/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1449 - val_loss: 0.8863\n",
            "Epoch 162/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.1441 - val_loss: 0.8815\n",
            "Epoch 163/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.1429 - val_loss: 0.8849\n",
            "Epoch 164/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.1411 - val_loss: 0.8868\n",
            "Epoch 165/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1390 - val_loss: 0.8899\n",
            "Epoch 166/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1379 - val_loss: 0.8946\n",
            "Epoch 167/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1363 - val_loss: 0.8961\n",
            "Epoch 168/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.1339 - val_loss: 0.9015\n",
            "Epoch 169/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1333 - val_loss: 0.9014\n",
            "Epoch 170/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1326 - val_loss: 0.9042\n",
            "Epoch 171/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1292 - val_loss: 0.9085\n",
            "Epoch 172/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1290 - val_loss: 0.9075\n",
            "Epoch 173/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1277 - val_loss: 0.9077\n",
            "Epoch 174/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1253 - val_loss: 0.9111\n",
            "Epoch 175/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.1240 - val_loss: 0.9122\n",
            "Epoch 176/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1235 - val_loss: 0.9159\n",
            "Epoch 177/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1210 - val_loss: 0.9209\n",
            "Epoch 178/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1200 - val_loss: 0.9192\n",
            "Epoch 179/200\n",
            "21/21 [==============================] - 14s 673ms/step - loss: 0.1190 - val_loss: 0.9204\n",
            "Epoch 180/200\n",
            "21/21 [==============================] - 14s 671ms/step - loss: 0.1169 - val_loss: 0.9242\n",
            "Epoch 181/200\n",
            "21/21 [==============================] - 14s 679ms/step - loss: 0.1159 - val_loss: 0.9258\n",
            "Epoch 182/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.1141 - val_loss: 0.9316\n",
            "Epoch 183/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.1136 - val_loss: 0.9307\n",
            "Epoch 184/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.1114 - val_loss: 0.9356\n",
            "Epoch 185/200\n",
            "21/21 [==============================] - 14s 678ms/step - loss: 0.1112 - val_loss: 0.9377\n",
            "Epoch 186/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.1088 - val_loss: 0.9406\n",
            "Epoch 187/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1084 - val_loss: 0.9412\n",
            "Epoch 188/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.1075 - val_loss: 0.9446\n",
            "Epoch 189/200\n",
            "21/21 [==============================] - 14s 672ms/step - loss: 0.1052 - val_loss: 0.9478\n",
            "Epoch 190/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1044 - val_loss: 0.9505\n",
            "Epoch 191/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.1034 - val_loss: 0.9534\n",
            "Epoch 192/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.1018 - val_loss: 0.9583\n",
            "Epoch 193/200\n",
            "21/21 [==============================] - 14s 677ms/step - loss: 0.1009 - val_loss: 0.9561\n",
            "Epoch 194/200\n",
            "21/21 [==============================] - 14s 678ms/step - loss: 0.0995 - val_loss: 0.9594\n",
            "Epoch 195/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.0986 - val_loss: 0.9640\n",
            "Epoch 196/200\n",
            "21/21 [==============================] - 14s 675ms/step - loss: 0.0969 - val_loss: 0.9697\n",
            "Epoch 197/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.0965 - val_loss: 0.9686\n",
            "Epoch 198/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.0948 - val_loss: 0.9699\n",
            "Epoch 199/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.0939 - val_loss: 0.9730\n",
            "Epoch 200/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.0929 - val_loss: 0.9749\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f48067c4810>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit( \n",
        "    [en_in_data, dec_in_data],\n",
        "    dec_tr_data, \n",
        "    batch_size=100, \n",
        "    epochs=200, \n",
        "    validation_split=0.2,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ugm4TIm1ihH3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6De2FK38i5Rg",
        "outputId": "9ef86a1d-5ddb-4455-a45b-08d990dd989b"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/Seq2seq_word2vec_model\")\n",
        "latent_dim=100\n",
        "model = models.load_model(\"/content/drive/MyDrive/Seq2seq_word2vec_model\")\n",
        "en_outputs,state_h_enc,state_c_enc = model.layers[6].output\n",
        "en_states=[state_h_enc,state_c_enc]\n",
        "en_model = Model(model.input[0],[en_outputs]+en_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4GPhi2KJ6Sj"
      },
      "outputs": [],
      "source": [
        "model = models.load_model(\"/content/drive/MyDrive/Seq2seq_word2vec_model\")\n",
        "en_outputs,state_h_enc,state_c_enc = model.layers[6].output\n",
        "en_states=[state_h_enc,state_c_enc]\n",
        "en_model = Model(model.input[0],[en_outputs]+en_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLVJzlAtjfX6"
      },
      "outputs": [],
      "source": [
        "dec_state_input_h = Input(shape=(100,))\n",
        "dec_state_input_c = Input(shape=(100,))\n",
        "dec_hidden_state_input = Input(shape=(200,100))\n",
        "dec_inputs = model.input[1]\n",
        "dec_emb_layer = model.layers[5]\n",
        "dec_lstm = model.layers[7]\n",
        "dec_embedding= dec_emb_layer(dec_inputs)\n",
        "dec_outputs2, state_h2, state_c2 = dec_lstm(dec_embedding, initial_state=[dec_state_input_h,dec_state_input_c])\n",
        "attention = model.layers[8]\n",
        "attn_out2 = attention([dec_outputs2,dec_hidden_state_input])\n",
        "merge2 = Concatenate(axis=-1)([dec_outputs2, attn_out2])\n",
        "dec_dense = model.layers[10]\n",
        "\n",
        "dec_outputs2 = dec_dense(merge2)\n",
        "dec_model = Model(\n",
        "[dec_inputs] + [dec_hidden_state_input,dec_state_input_h,dec_state_input_c],\n",
        "[dec_outputs2] + [state_h2, state_c2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0f3CN0Cj1i-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "reverse_target_word_index = tr_tokenizer.index_word\n",
        "reverse_source_word_index = in_tokenizer.index_word\n",
        "target_word_index = tr_tokenizer.word_index\n",
        "reverse_target_word_index[0]=' '\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    #get the encoder output and states by passing the input sequence\n",
        "    en_out, en_h, en_c= en_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "    stop_condition = False\n",
        "    #append every predicted word in decoded sentence\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition: \n",
        "        #get predicted output, hidden and cell state.\n",
        "        output_words, dec_h, dec_c= dec_model.predict([target_seq] + [en_out,en_h, en_c])\n",
        "        \n",
        "        #get the index and from the dictionary get the word for that index.\n",
        "        word_index = np.argmax(output_words[0, -1, :])\n",
        "        text_word = reverse_target_word_index[word_index]\n",
        "        decoded_sentence += text_word +\" \"\n",
        "        if text_word == \"end\" or len(decoded_sentence) > max_len_text:\n",
        "              stop_condition = True\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = word_index\n",
        "        en_h, en_c = dec_h, dec_c\n",
        "  #return the decoded sentence\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "DynG5ZKzj3_C",
        "outputId": "b3d446cf-ca5b-4d46-bef1-1b9054d7904c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'confluent consolidation seen lateral aspect left lung base regions scattered focal opacities present within right left lungs definite correlate seen scattered opacities prior torso ct although developing atelectasis seen left base prior ct examination cardiac mediastinal contours probably within normal limits given technique pneumothorax seen although right lateral lung within imaged field'"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(X_test)[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQqd7llaHi9m",
        "outputId": "3c8f5fbe-76aa-4afe-9fc9-f8a317017e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_START_ interval development of multifocal pneumonia _END_\n"
          ]
        }
      ],
      "source": [
        "sum1=list(y_test)[3]\n",
        "print(sum1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWvgqWUqL86J",
        "outputId": "cbf521be-f191-4f5b-bb49-0f6824ffa87c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predicted summary: unchanged appearance of the chest tube with known large right pleural effusion new retrocardiac opacity most likely representing areas of small pleural effusion unchanged left lower lobe atelectasis end \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#inp_review = input(\"Enter : \")\n",
        "#print(Review :,inp_review)\n",
        "\n",
        "#inp_review = clean(inp_review,\"inputs\")\n",
        "\n",
        "# i need some other mechanism to celan the inpout text data\n",
        "#inp_review = ' '.join(inp_review)\n",
        "input_review=list(X_test)[3]\n",
        "inp_x= in_tokenizer.texts_to_sequences([input_review]) \n",
        "inp_x= pad_sequences(inp_x,  maxlen=max_len_text, padding='post')\n",
        " \n",
        "summary=decode_sequence(inp_x.reshape(1,max_len_text))\n",
        "if 'eos' in summary :\n",
        "  summary=summary.replace('eos','')\n",
        "print(\"\\nPredicted summary:\",summary);print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgJtdzMLU0jg"
      },
      "source": [
        "So this is the use of rouge metric there are several different ways of using rouge metric per sentence either you can calcukate average but don't know why sentences gives rouge 2 scores zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejJP5WJ3Occm",
        "outputId": "9ad27772-187d-41b6-d922-eb189fbd1503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'rouge-1': {'r': 0.14285714285714285, 'p': 0.04, 'f': 0.06249999658203144}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.14285714285714285, 'p': 0.04, 'f': 0.06249999658203144}}]\n"
          ]
        }
      ],
      "source": [
        "from rouge import Rouge \n",
        "hypothesis = summary\n",
        "reference = sum1\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(hypothesis, reference)\n",
        "print(scores)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Seq2seqwithAttention_ClinicalBert_embeddings.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "42fac95310d93a08864c5a2101c7cf7fb19f67ebdd00fbf44f60db3e9679aedd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
