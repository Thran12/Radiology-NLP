{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0vAbNuC4u9ET",
        "outputId": "76b106ab-a2c2-4eaa-b25f-cc3c78ad490a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fae77d03-7f73-44a1-99b3-34728226e165\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Original_position</th>\n",
              "      <th>findings</th>\n",
              "      <th>impressions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>there is no acute intracranial hemorrhage, mas...</td>\n",
              "      <td>1. no acute intracranial hemorrhage or mass ef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ap, lateral, and oblique views of the left foo...</td>\n",
              "      <td>comminuted intra-articular fracture proximal p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>the procedure was explained to the patient. a ...</td>\n",
              "      <td>uncomplicated ultrasound and fluoroscopically ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>the ventricles and extra-axial spaces are norm...</td>\n",
              "      <td>3-mm lesion within the left cerebellar hemisph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>there is no evidence of fracture, dislocation,...</td>\n",
              "      <td>no evidence of fracture or subluxation.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fae77d03-7f73-44a1-99b3-34728226e165')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fae77d03-7f73-44a1-99b3-34728226e165 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fae77d03-7f73-44a1-99b3-34728226e165');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  Original_position  \\\n",
              "0           0                  0   \n",
              "1           1                  1   \n",
              "2           2                  2   \n",
              "3           3                  3   \n",
              "4           4                  4   \n",
              "\n",
              "                                            findings  \\\n",
              "0  there is no acute intracranial hemorrhage, mas...   \n",
              "1  ap, lateral, and oblique views of the left foo...   \n",
              "2  the procedure was explained to the patient. a ...   \n",
              "3  the ventricles and extra-axial spaces are norm...   \n",
              "4  there is no evidence of fracture, dislocation,...   \n",
              "\n",
              "                                         impressions  \n",
              "0  1. no acute intracranial hemorrhage or mass ef...  \n",
              "1  comminuted intra-articular fracture proximal p...  \n",
              "2  uncomplicated ultrasound and fluoroscopically ...  \n",
              "3  3-mm lesion within the left cerebellar hemisph...  \n",
              "4         no evidence of fracture or subluxation.     "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df1=pd.read_csv('/content/drive/MyDrive/Extracted_Data.csv')\n",
        "df1.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTAmjlKDvWQ1",
        "outputId": "0fcd7881-29ae-40e2-9936-c63c7ccb3e3c"
      },
      "outputs": [],
      "source": [
        "x=list(df1.columns)\n",
        "x.remove('findings')\n",
        "x.remove('impressions')\n",
        "df2=df1.drop(x,axis=1)\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL4IP1TkvdwS",
        "outputId": "9d690e73-81d7-456b-ea89-95804bdeaeaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "findings       0\n",
            "impressions    0\n",
            "dtype: int64\n",
            "findings       0\n",
            "impressions    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df2.isna().sum())\n",
        "df2.dropna(axis=0,inplace=True)\n",
        "print(df2.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klJdhGNvgrOn",
        "outputId": "7192b093-2b9f-4b8b-f64f-4b333d4bbc01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxw4FXOgvlc8"
      },
      "outputs": [],
      "source": [
        "import regex as re\n",
        "from nltk.corpus import stopwords \n",
        "stop_words = set(stopwords.words('english')) \n",
        "def clean_data(list1,name,new_list1):\n",
        "    for i in list1:\n",
        "        i=str(i)\n",
        "        new_string = re.sub(r'[^\\w\\s]', '', i)\n",
        "        pattern = r'[0-9]'\n",
        "        new_string1 = re.sub(pattern, '', new_string)\n",
        "        new_string2 = re.sub(r'\\([^)]*\\)', '', new_string1)\n",
        "        new_string1=new_string2.lower()\n",
        "        if name=='findings':\n",
        "            tokens = [w for w in new_string1.split() if not w in stop_words]\n",
        "            tokens=' '.join(tokens)\n",
        "            new_list1.append(tokens)\n",
        "        elif name=='impressions':\n",
        "            new_list1.append(new_string1)\n",
        "    return new_list1\n",
        "x1=[]\n",
        "list1=clean_data(list(df2['findings']),df2['findings'].name,x1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI0FIdTevl5T"
      },
      "outputs": [],
      "source": [
        "x2=[]\n",
        "list2=clean_data(list(df2['impressions']),df2['impressions'].name,x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ-CuZD-xE-5"
      },
      "outputs": [],
      "source": [
        "def clean_further(list1):\n",
        "    list5=[]\n",
        "    for i in list1:\n",
        "        i=str(i)\n",
        "        list1=i.split(' ')\n",
        "        for i in range(list1.count('')):\n",
        "            list1.remove('')\n",
        "        x1=' '.join(list1)\n",
        "        list5.append(x1)\n",
        "    return list5\n",
        "list6=clean_further(list1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoVBUV7Yxnqm"
      },
      "outputs": [],
      "source": [
        "list7=clean_further(list2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AUuTd84Txpkt",
        "outputId": "4385aea0-1770-4b60-999c-9c88eb8c9782"
      },
      "outputs": [],
      "source": [
        "df3=pd.DataFrame({'findings':list6,\n",
        "                'impression':list7})\n",
        "df3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwbsvWcExsS2"
      },
      "outputs": [],
      "source": [
        "df3['impression'] = df3['impression'].apply(lambda x : '_START_ '+ x + ' _END_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKqq9VDcxz_W",
        "outputId": "da15a6d8-45aa-4608-dc60-b581ab9fc5cf"
      },
      "outputs": [],
      "source": [
        "import random as rnd\n",
        "def get_any_data(times,which):\n",
        "    for i in range(times):\n",
        "        x1=rnd.randint(0,len(df3['findings']))\n",
        "        print(x1)\n",
        "        print(df3[which][x1])\n",
        "        print(df3['impression'][x1])\n",
        "        print('--------')\n",
        "get_any_data(3,'findings')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "B7pzdEPgx3or",
        "outputId": "83cb0f3d-368e-426b-c0c7-fb089e5afba4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "# populate the lists with sentence lengths\n",
        "for i in df3['findings']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "for i in df3['impression']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1kAmWFCx9HK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(df3['findings'],df3['impression'],test_size=0.1,random_state=42,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9kvcYelyFL6",
        "outputId": "c5a7b971-5a32-4f4a-aee9-941fb48a2633"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2568,)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEtw2uKntGnn",
        "outputId": "f1d869bb-3909-44c1-9777-a370d916259d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "209\n"
          ]
        }
      ],
      "source": [
        "list_len=[len(i.split()) for i in df3['impression']]\n",
        "print(max(list_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NItNCoWsyI61"
      },
      "outputs": [],
      "source": [
        "max_len_text=200\n",
        "max_len_summary=190\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "in_tokenizer = Tokenizer()\n",
        "in_tokenizer.fit_on_texts(X_train)\n",
        "tr_tokenizer = Tokenizer()\n",
        "tr_tokenizer.fit_on_texts(y_train)\n",
        "X_train= in_tokenizer.texts_to_sequences(X_train) \n",
        "y_train= tr_tokenizer.texts_to_sequences(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkSkqfluycDn"
      },
      "outputs": [],
      "source": [
        "en_in_data= pad_sequences(X_train,  maxlen=max_len_text, padding='post') \n",
        "dec_data= pad_sequences(y_train,  maxlen=max_len_summary, padding='post')\n",
        "dec_in_data = dec_data[:,:-1]\n",
        "dec_tr_data = dec_data.reshape(len(dec_data),max_len_summary,1)[:,1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBiCWPknMyAU"
      },
      "outputs": [],
      "source": [
        "x_voc_size   =  len(in_tokenizer.word_index) +1\n",
        "y_voc_size   =  len(tr_tokenizer.word_index) +1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqJDj8TXhrxn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_wy5e83306W"
      },
      "outputs": [],
      "source": [
        "size_of_vocab=len(in_tokenizer.word_index)+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_V4qX1ZtjT1"
      },
      "source": [
        "So this the technique of using embedding matrix and embedding vectors as embedding layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX5wpyB1mveb",
        "outputId": "47f9405c-a503-49cc-bd93-400cada78842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 44082 word vectors.\n",
            "(100,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "#embedding Layer creation\n",
        "from gensim.models import Word2Vec\n",
        "best_model=Word2Vec.load('/content/drive/MyDrive/word2vec+fastText/word2vec.model')\n",
        "vocab_len_size = best_model.wv.index2word\n",
        "dict1={}\n",
        "for i in range(len(best_model.wv.index2word)):\n",
        "  keys=list(best_model.wv.vocab.keys())[i]\n",
        "  vector1=best_model.wv.vectors[i]\n",
        "  dict1[f'{keys}']=vector1\n",
        "with open('/content/drive/MyDrive/custom_embeddings_word2vec.txt', 'w+') as f:\n",
        "    for token, vector in dict1.items():\n",
        "        vector_str = ' '.join([str(v) for v in vector])\n",
        "        f.write(f'{token} {vector_str}\\n')\n",
        "embeddings_index = dict()\n",
        "f = open('/content/drive/MyDrive/custom_embeddings_word2vec.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "x_voc_size=44082\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "from keras.layers import Embedding\n",
        "embedding_matrix = np.zeros((x_voc_size, 100))\n",
        "\n",
        "#..so here the x_voc_size need to be replace by 44082 and 130 need to be replaced with 100\n",
        "\n",
        "for word, i in in_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(len(dict1)+1,\n",
        "                            130,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_len_text,\n",
        "                            trainable=False)\n",
        "#print(embedding_matrix.shape)\n",
        "'''list_embeddings=list(dict1.keys())\n",
        "if 'endotracheal' in list_embeddings:\n",
        "  print(True)\n",
        "else:\n",
        "  print(False)'''\n",
        "embedding_layer=Embedding(x_voc_size,100,weights=[embedding_matrix],input_length=max_len_text,trainable=False)\n",
        "print(embedding_matrix[3].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uue9IHdBuX6J",
        "outputId": "2f449321-0c6b-410d-fc9d-3282d71304fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44082"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(embedding_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKTMzKQVwTSC"
      },
      "outputs": [],
      "source": [
        "#import json\n",
        "#with open('/content/drive/MyDrive/data.json') as json_file:\n",
        " #   data = json.load(json_file)\n",
        "  #  print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UBskFuNwSV6"
      },
      "outputs": [],
      "source": [
        "#list1=list(data.values())\n",
        "#print(list1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVnffMf6vSxL"
      },
      "source": [
        "Using Clinical Bert Embeddings.Just Clinical Bert.\n",
        "Next target is to use Clinical Biobert as your embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4RzGgMZht6I",
        "outputId": "a177852c-2aa1-45e6-e2e3-e1f6f85a796e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        multiple             4408200     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200, 100),   80400       ['embedding_1[0][0]']            \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 200, 100),   80400       ['lstm[0][0]']                   \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 100)    444300      ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 200, 100),   80400       ['lstm_1[0][0]']                 \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  [(None, None, 100),  80400       ['embedding[0][0]',              \n",
            "                                 (None, 100),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 100)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, None, 100)    0           ['lstm_4[0][0]',                 \n",
            "                                                                  'lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " concat_layer1 (Concatenate)    (None, None, 200)    0           ['lstm_4[0][0]',                 \n",
            "                                                                  'attention[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 44082)  8860482     ['concat_layer1[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,034,582\n",
            "Trainable params: 9,626,382\n",
            "Non-trainable params: 4,408,200\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "import tensorflow.keras.layers\n",
        "import tensorflow.keras.models\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.layers import Attention\n",
        "\n",
        "K.clear_session() \n",
        "latent_dim = 100\n",
        " \n",
        "#create input object of total number of encoder words\n",
        "#en_inputs = Input(shape=(max_len_text,)) \n",
        "#en_embedding = Embedding(x_voc_size, latent_dim,trainable=True)(en_inputs) \n",
        "\n",
        "#... adding a custom layer in place of this embedding layer for custom embedding scenario\n",
        "sequence_input = Input(shape=(max_len_text,), dtype='int32')\n",
        "en_embedding = embedding_layer(sequence_input)\n",
        "\n",
        "\n",
        "#1st LSTM Layer\n",
        "en_lstm1= LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "en_outputs1, state_h1, state_c1= en_lstm1(en_embedding) \n",
        "#2nd LSTM Layer\n",
        "en_lstm2= LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "en_outputs2, state_h2, state_c2= en_lstm2(en_outputs1) \n",
        "#3rd LSTM Layer\n",
        "en_lstm3= LSTM(latent_dim,return_sequences=True,return_state=True)\n",
        "en_outputs3 , state_h3 , state_c3= en_lstm3(en_outputs2)\n",
        "#encoder states\n",
        "en_states= [state_h3, state_c3]\n",
        "\n",
        "#---------------------------------\n",
        "\n",
        "\n",
        "# Decoder. \n",
        "'''dec_inputs = Input(shape=(None,)) \n",
        "\n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim) \n",
        "dec_embedding = dec_emb_layer(dec_inputs) '''\n",
        "\n",
        "#.using the custom decoder Layer\n",
        "#................................................\n",
        "\n",
        "dec_inputs = Input(shape=(None,), dtype='int32')\n",
        "dec_embedding = embedding_layer(dec_inputs)\n",
        " \n",
        "#initialize decoder's LSTM layer with the output states of encoder\n",
        "dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "dec_outputs, *_ = dec_lstm(dec_embedding,initial_state=en_states) \n",
        "\n",
        "'''# Decoder. \n",
        "dec_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim) \n",
        "dec_embedding = dec_emb_layer(dec_inputs) \n",
        " \n",
        "#initialize decoder's LSTM layer with the output states of encoder\n",
        "dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "dec_outputs, *_ = dec_lstm(dec_embedding,initial_state=en_states)'''\n",
        "\n",
        "#Attention layer\n",
        "attention =Attention()\n",
        "attn_out = attention([dec_outputs,en_outputs3])\n",
        " \n",
        "#Concatenate the attention output with the decoder outputs\n",
        "merge=Concatenate(axis=-1, name='concat_layer1')([dec_outputs,attn_out]) \n",
        "#Dense layer (output layer)\n",
        "dec_dense = Dense(x_voc_size, activation='softmax') \n",
        "dec_outputs = dec_dense(merge) \n",
        "\n",
        "model = Model([sequence_input, dec_inputs],dec_outputs) \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljtt0y3dh1Ct"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KhnEVPeiZlI"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "#maybe changing the optimizer and loss function can help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRXSLKZQibx_",
        "outputId": "f6fe3b56-163c-4102-b518-40f08a8a3b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "21/21 [==============================] - 16s 714ms/step - loss: 5.0921 - val_loss: 1.5014\n",
            "Epoch 2/200\n",
            "21/21 [==============================] - 14s 657ms/step - loss: 1.2654 - val_loss: 1.1841\n",
            "Epoch 3/200\n",
            "21/21 [==============================] - 14s 659ms/step - loss: 1.0517 - val_loss: 1.0383\n",
            "Epoch 4/200\n",
            "21/21 [==============================] - 14s 660ms/step - loss: 0.9664 - val_loss: 1.0023\n",
            "Epoch 199/200\n",
            "21/21 [==============================] - 14s 676ms/step - loss: 0.0939 - val_loss: 0.9730\n",
            "Epoch 200/200\n",
            "21/21 [==============================] - 14s 674ms/step - loss: 0.0929 - val_loss: 0.9749\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f48067c4810>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit( \n",
        "    [en_in_data, dec_in_data],\n",
        "    dec_tr_data, \n",
        "    batch_size=100, \n",
        "    epochs=200, \n",
        "    validation_split=0.2,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ugm4TIm1ihH3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6De2FK38i5Rg",
        "outputId": "9ef86a1d-5ddb-4455-a45b-08d990dd989b"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/Seq2seq_word2vec_model\")\n",
        "latent_dim=100\n",
        "model = models.load_model(\"/content/drive/MyDrive/Seq2seq_word2vec_model\")\n",
        "en_outputs,state_h_enc,state_c_enc = model.layers[6].output\n",
        "en_states=[state_h_enc,state_c_enc]\n",
        "en_model = Model(model.input[0],[en_outputs]+en_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4GPhi2KJ6Sj"
      },
      "outputs": [],
      "source": [
        "model = models.load_model(\"/content/drive/MyDrive/Seq2seq_word2vec_model\")\n",
        "en_outputs,state_h_enc,state_c_enc = model.layers[6].output\n",
        "en_states=[state_h_enc,state_c_enc]\n",
        "en_model = Model(model.input[0],[en_outputs]+en_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLVJzlAtjfX6"
      },
      "outputs": [],
      "source": [
        "dec_state_input_h = Input(shape=(100,))\n",
        "dec_state_input_c = Input(shape=(100,))\n",
        "dec_hidden_state_input = Input(shape=(200,100))\n",
        "dec_inputs = model.input[1]\n",
        "dec_emb_layer = model.layers[5]\n",
        "dec_lstm = model.layers[7]\n",
        "dec_embedding= dec_emb_layer(dec_inputs)\n",
        "dec_outputs2, state_h2, state_c2 = dec_lstm(dec_embedding, initial_state=[dec_state_input_h,dec_state_input_c])\n",
        "attention = model.layers[8]\n",
        "attn_out2 = attention([dec_outputs2,dec_hidden_state_input])\n",
        "merge2 = Concatenate(axis=-1)([dec_outputs2, attn_out2])\n",
        "dec_dense = model.layers[10]\n",
        "\n",
        "dec_outputs2 = dec_dense(merge2)\n",
        "dec_model = Model(\n",
        "[dec_inputs] + [dec_hidden_state_input,dec_state_input_h,dec_state_input_c],\n",
        "[dec_outputs2] + [state_h2, state_c2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0f3CN0Cj1i-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "reverse_target_word_index = tr_tokenizer.index_word\n",
        "reverse_source_word_index = in_tokenizer.index_word\n",
        "target_word_index = tr_tokenizer.word_index\n",
        "reverse_target_word_index[0]=' '\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    #get the encoder output and states by passing the input sequence\n",
        "    en_out, en_h, en_c= en_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "    stop_condition = False\n",
        "    #append every predicted word in decoded sentence\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition: \n",
        "        #get predicted output, hidden and cell state.\n",
        "        output_words, dec_h, dec_c= dec_model.predict([target_seq] + [en_out,en_h, en_c])\n",
        "        \n",
        "        #get the index and from the dictionary get the word for that index.\n",
        "        word_index = np.argmax(output_words[0, -1, :])\n",
        "        text_word = reverse_target_word_index[word_index]\n",
        "        decoded_sentence += text_word +\" \"\n",
        "        if text_word == \"end\" or len(decoded_sentence) > max_len_text:\n",
        "              stop_condition = True\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = word_index\n",
        "        en_h, en_c = dec_h, dec_c\n",
        "  #return the decoded sentence\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "DynG5ZKzj3_C",
        "outputId": "b3d446cf-ca5b-4d46-bef1-1b9054d7904c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'confluent consolidation seen lateral aspect left lung base regions scattered focal opacities present within right left lungs definite correlate seen scattered opacities prior torso ct although developing atelectasis seen left base prior ct examination cardiac mediastinal contours probably within normal limits given technique pneumothorax seen although right lateral lung within imaged field'"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(X_test)[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQqd7llaHi9m",
        "outputId": "3c8f5fbe-76aa-4afe-9fc9-f8a317017e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_START_ interval development of multifocal pneumonia _END_\n"
          ]
        }
      ],
      "source": [
        "sum1=list(y_test)[3]\n",
        "print(sum1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWvgqWUqL86J",
        "outputId": "cbf521be-f191-4f5b-bb49-0f6824ffa87c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predicted summary: unchanged appearance of the chest tube with known large right pleural effusion new retrocardiac opacity most likely representing areas of small pleural effusion unchanged left lower lobe atelectasis end \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#inp_review = input(\"Enter : \")\n",
        "#print(“Review :”,inp_review)\n",
        "\n",
        "#inp_review = clean(inp_review,\"inputs\")\n",
        "\n",
        "# i need some other mechanism to celan the inpout text data\n",
        "#inp_review = ' '.join(inp_review)\n",
        "input_review=list(X_test)[3]\n",
        "inp_x= in_tokenizer.texts_to_sequences([input_review]) \n",
        "inp_x= pad_sequences(inp_x,  maxlen=max_len_text, padding='post')\n",
        " \n",
        "summary=decode_sequence(inp_x.reshape(1,max_len_text))\n",
        "if 'eos' in summary :\n",
        "  summary=summary.replace('eos','')\n",
        "print(\"\\nPredicted summary:\",summary);print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgJtdzMLU0jg"
      },
      "source": [
        "So this is the use of rouge metric there are several different ways of using rouge metric per sentence either you can calcukate average but don't know why sentences gives rouge 2 scores zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejJP5WJ3Occm",
        "outputId": "9ad27772-187d-41b6-d922-eb189fbd1503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'rouge-1': {'r': 0.14285714285714285, 'p': 0.04, 'f': 0.06249999658203144}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.14285714285714285, 'p': 0.04, 'f': 0.06249999658203144}}]\n"
          ]
        }
      ],
      "source": [
        "from rouge import Rouge \n",
        "hypothesis = summary\n",
        "reference = sum1\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(hypothesis, reference)\n",
        "print(scores)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Seq2seqwithAttention_ClinicalBert_embeddings.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "42fac95310d93a08864c5a2101c7cf7fb19f67ebdd00fbf44f60db3e9679aedd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
